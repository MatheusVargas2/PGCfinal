{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets GunControl, GayMarriage and RestaurantReviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reviews_options_datasets(arquivo, name_id):\n",
    "    file = open(\"../Datasets/Originais/\" + arquivo, \"r\")\n",
    "    linhas = []\n",
    "    \n",
    "    for linha in file:\n",
    "        if not re.search(\"MouseUp\", linha) == None:\n",
    "            inicio = min(re.search(\"MouseUp\", linha).span()[0], re.search(\"KeyDown\", linha).span()[0], re.search(\"KeyUp\", linha).span()[0])\n",
    "            ponto_virgula = re.search(\";\", linha).span()[0]\n",
    "            while ponto_virgula < inicio:\n",
    "                linha = re.sub(';', ' ', linha, 1)\n",
    "                ponto_virgula = re.search(\";\", linha).span()[0]\n",
    "        linhas.append(linha)\n",
    "        \n",
    "    \n",
    "    for i in range(0,len(linhas)):\n",
    "        linhas[i] = linhas[i].replace(\"\\t\",\";\")\n",
    "        linhas[i] = linhas[i].replace(\"\\n\",\"\")\n",
    "        linhas[i] = linhas[i].split(\";\")\n",
    "        \n",
    "    colunas_max = 0\n",
    "    for i in linhas:\n",
    "        colunas_max = max(len(i), colunas_max)\n",
    "    \n",
    "    df = pd.DataFrame(linhas[1:], columns=pd.concat([pd.Series(linhas[0]),pd.Series(range(0,colunas_max-len(linhas[0])))]))\n",
    "    df[\"User_Label\"] = df[\"AccessKey\"]\n",
    "    df[\"Sample_Label\"] = name_id + \"|\" + df[\"AccessKey\"] + \"|\" + df[\"Task\"]  \n",
    "    df.to_csv(\"../Datasets/Tratados/\" + arquivo, index=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df1 = reviews_options_datasets(\"GunControl_400.csv\", \"gun\")\n",
    "df2 = reviews_options_datasets(\"GayMarriage_400.csv\", \"gay\")\n",
    "df3 = reviews_options_datasets(\"ReviewAMT_500_t.csv\", \"rest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GunControl Dataset\n",
    "df1.shape\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GayMarriage Dataset\n",
    "df2.shape\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RestaurantReview Dataset\n",
    "df3.shape\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Informações básicas dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Quantidade de caracteres ---\")\n",
    "total = 0\n",
    "tamanho = 0\n",
    "for i in df1.ReviewText:\n",
    "    tamanho = tamanho + len(i)\n",
    "total = total + tamanho\n",
    "print(\"Gun: \", tamanho)\n",
    "print(\"Média: \", tamanho/len(df1.ReviewText))\n",
    "\n",
    "tamanho = 0\n",
    "for i in df2.ReviewText:\n",
    "    tamanho = tamanho + len(i)\n",
    "total = total + tamanho\n",
    "print(\"\\nGay: \", tamanho)\n",
    "print(\"Média: \", tamanho/len(df2.ReviewText))\n",
    "\n",
    "tamanho = 0\n",
    "for i in df3.ReviewText:\n",
    "    tamanho = tamanho + len(i)\n",
    "total = total + tamanho\n",
    "print(\"\\nRestaurante: \", tamanho)\n",
    "print(\"Média: \", tamanho/len(df3.ReviewText))\n",
    "    \n",
    "print(\"\\nTotal: \", total)\n",
    "print(\"Média: \", total/(len(df1.ReviewText)+len(df2.ReviewText)+len(df3.ReviewText)))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\\n--- Quantidade de textos ---\")\n",
    "print(\"Gun: \", len(df1))\n",
    "print(\"Gay: \", len(df2))\n",
    "print(\"Restaurante: \", len(df3))\n",
    "print(\"Total: \", len(df1)+len(df2)+len(df3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verifica se o problema de ter texto em campo de caracteres foi corrigido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verifica se há texto em outros campos\n",
    "\n",
    "def tamanho(x):\n",
    "    return len(x)\n",
    "\n",
    "print(sum([df1[\"ReviewMeta\"][df1[\"ReviewMeta\"].apply(tamanho) > 27].size,df2[\"ReviewMeta\"][df2[\"ReviewMeta\"].apply(tamanho) > 27].size,df3[\"ReviewMeta\"][df3[\"ReviewMeta\"].apply(tamanho) > 27].size]))\n",
    "print(sum([df1[0][df1[0].apply(tamanho) > 27].size,df2[0][df2[0].apply(tamanho) > 29].size,df3[0][df3[0].apply(tamanho) > 27].size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets 1.6MM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def millions_dataset(range_inicio, range_fim):\n",
    "    count = 0\n",
    "    linhas = []\n",
    "\n",
    "    # Tratamentos básicos\n",
    "    for i in tqdm_notebook(range(range_inicio, range_fim)):\n",
    "        if path.exists(\"../Datasets/Originais/Keystrokes/files/\" + str(i) + \"_keystrokes.txt\"):\n",
    "            file = open(\"../Datasets/Originais/Keystrokes/files/\" + str(i) + \"_keystrokes.txt\", \"r\")\n",
    "            count += 1\n",
    "\n",
    "            for linha in file:\n",
    "                linha = linha.replace(\"\\n\",\"\")\n",
    "                linha = linha.split(\"\\t\")\n",
    "                if len(linha) > 9:\n",
    "                    linha[8] = linha[9]\n",
    "                    linha.pop()\n",
    "                if not (linha[0] == 'PARTICIPANT_ID' and count > 1):\n",
    "                    linhas.append(linha)\n",
    "\n",
    "    dados = pd.DataFrame(data=linhas[1:], columns=linhas[0])\n",
    "\n",
    "    \n",
    "    # Converter para o formato padrão\n",
    "    amostras = []    # lista para salvar as amostras tratadas\n",
    "    qtd_cols = 0     # definir a qtd de colunas (maior amostra)\n",
    "    for user in tqdm_notebook(dados.PARTICIPANT_ID.unique()):\n",
    "        aux1 = dados[dados.PARTICIPANT_ID == user]\n",
    "\n",
    "        for section in aux1.TEST_SECTION_ID.unique():\n",
    "            aux2 = aux1[aux1.TEST_SECTION_ID == section]\n",
    "\n",
    "            infos = list(aux2.iloc[0, 0:3])\n",
    "            keys = []\n",
    "            for i in range(len(aux2)):\n",
    "                keys.append(str(aux2.iloc[i, 5]) + \" KeyDown \" + str(aux2.iloc[i, 8]))\n",
    "                keys.append(str(aux2.iloc[i, 6]) + \" KeyUp \" + str(aux2.iloc[i, 8]))\n",
    "\n",
    "            keys.sort()\n",
    "            amostra = infos + keys\n",
    "            if len(amostra) > qtd_cols:\n",
    "                qtd_cols = len(infos + keys)\n",
    "\n",
    "            amostras.append(amostra)\n",
    "\n",
    "    df = pd.DataFrame(amostras, columns=['user_ID', 'section', 'sentence'] + list(range(qtd_cols-3)))\n",
    "    \n",
    "    # Cria campos user_label e sample_label\n",
    "    for user in df[\"user_ID\"].unique():\n",
    "        if (df[\"user_ID\"] == user).sum() != 15:\n",
    "            print(\"AAA\")\n",
    "            df = df[df[\"user_ID\"] != user]\n",
    "    df[\"User_Label\"] = df[\"user_ID\"].astype(int).astype(str)\n",
    "    df[\"Sample_Label\"] = df[\"user_ID\"].astype(int).astype(str) + \"|\" + df[\"section\"].astype(str)\n",
    "    \n",
    "    # Salva base tratada\n",
    "    df.to_csv(\"../Datasets/Tratados/keystrokes/keystrokes_\" + str(range_inicio) + \"_\" + str(range_fim) + \".csv\")\n",
    "    print(\"Qtd. Usuários:\", count)\n",
    "    return df\n",
    "\n",
    "for i in range(0,48):\n",
    "    df = millions_dataset(10000*i, 10000*(i+1))\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_datasets = []\n",
    "for i in range(10):\n",
    "    lista_datasets.append(pd.read_csv(\"../Datasets/Tratados/keystrokes/keystrokes_\" + str(i*10000) + \"_\" + str((i+1)*10000) + \".csv\", low_memory=False))\n",
    "\n",
    "dataset_full = pd.concat(lista_datasets)\n",
    "dataset_full.to_csv(\"../Datasets/Tratados/keystrokes/keystrokes_FULL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agrupa dataset 15 -> 5 amostras (3 -> 1 amostra) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big = pd.read_csv(\"../Datasets/Tratados/keystrokes/keystrokes_0_10000.csv\", index=False)\n",
    "\n",
    "# inicialização\n",
    "i = 0\n",
    "\n",
    "fim_1 = 0\n",
    "for j in big.iloc[i, :-2]:\n",
    "    if j == \"\":\n",
    "        break\n",
    "    fim_1+=1\n",
    "\n",
    "fim_2 = 0\n",
    "for j in big.iloc[i+1, :-2]:\n",
    "    if j == \"\":\n",
    "        break\n",
    "    fim_2+=1\n",
    "\n",
    "fim_3 = 0\n",
    "for j in big.iloc[i+2, :-2]:\n",
    "    if j == \"\":\n",
    "        break\n",
    "    fim_3+=1\n",
    "\n",
    "dados = pd.concat([big.iloc[i, :fim_1], big.iloc[i+1, :fim_2], big.iloc[i+2, :fim_3]])\n",
    "label = big.iloc[i, [-2, -1]]\n",
    "\n",
    "df_modelo = pd.DataFrame(dados).reset_index(drop=True).transpose()\n",
    "df_modelo[\"User_Label\"] = label[0]\n",
    "df_modelo[\"Sample_Label\"] = label[1]\n",
    "\n",
    "for i in range(3,len(big),3):\n",
    "    fim_1 = 0\n",
    "    for j in big.iloc[i, :-2]:\n",
    "        if j == \"\":\n",
    "            break\n",
    "        fim_1+=1\n",
    "\n",
    "    fim_2 = 0\n",
    "    for j in big.iloc[i+1, :-2]:\n",
    "        if j == \"\":\n",
    "            break\n",
    "        fim_2+=1\n",
    "\n",
    "    fim_3 = 0\n",
    "    for j in big.iloc[i+2, :-2]:\n",
    "        if j == \"\":\n",
    "            break\n",
    "        fim_3+=1\n",
    "\n",
    "    dados = pd.concat([big.iloc[i, :fim_1], big.iloc[i+1, :fim_2], big.iloc[i+2, :fim_3]])\n",
    "    label = big.iloc[i, [-2, -1]]\n",
    "    \n",
    "    df_aux = pd.DataFrame(dados).reset_index(drop=True).transpose()\n",
    "    df_aux[\"User_Label\"] = label[0]\n",
    "    df_aux[\"Sample_Label\"] = label[1]\n",
    "    \n",
    "    df_modelo = pd.concat([df_modelo, df_aux])\n",
    "    \n",
    "df_modelo.to_csv(\"../Datasets/Tratados/keystrokes/keystrokes_0_10000_AGRUP_3.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
